{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layer 1\n",
    "filter1_size = 5\n",
    "num_filter1 = 16\n",
    "\n",
    "# Convolutional layer 2\n",
    "filter2_size = 5\n",
    "num_filter2 = 36\n",
    "\n",
    "# Fully-connected layer \n",
    "fc_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "data = MNIST(data_dir=\"data/MNIST/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data.x_train\n",
    "y_train = data.y_train\n",
    "y_train_cls = data.y_train_cls\n",
    "\n",
    "x_test = data.x_test\n",
    "y_test = data.y_test\n",
    "y_test_cls = data.y_test_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = data.num_train\n",
    "num_test = data.num_test\n",
    "num_classes = data.num_classes\n",
    "# Image shape\n",
    "img_shape = data.img_shape\n",
    "img_size_flat = data.img_size_flat\n",
    "# Num channel color\n",
    "num_channels = data.num_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Helper-function for ploting images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting 9x9 images in a grid, writting true and predict labels bellow each image.\n",
    "def plot_images(images, true_labels, pred_labels=None):\n",
    "    assert (len(images) == len(true_labels))\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(0.3, 0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Set images\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "        \n",
    "        # Set labels\n",
    "        if (pred_labels == None):\n",
    "            xlabel = \"True label: {0}\".format(true_labels[i])\n",
    "        else:\n",
    "            xlabel = \"True label: {0}, Predict label: {1}\".format(true_labels[i], pred_labels[i])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(x_test[:9], y_test_cls[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Helper-function for create variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weight(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "def new_bias(length):\n",
    "    return tf.Variable(tf.constant(value=0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Helper-function for create Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input, \n",
    "                  num_input_channels,\n",
    "                  filter_size, \n",
    "                  num_filters, \n",
    "                  use_pooling):\n",
    "    shape = (filter_size, filter_size, num_input_channels, num_filters)\n",
    "    weights = new_weight(shape)\n",
    "    biases = new_bias(num_filters)\n",
    "    layer = tf.nn.conv2d(input=input, \n",
    "                         filter=weights, \n",
    "                         strides=[1,2,2,1], \n",
    "                         padding=\"SAME\")\n",
    "    # Add bias\n",
    "    layer = layer + biases\n",
    "    # Use pooling\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer, \n",
    "                               ksize=[1, 2, 2, 1], \n",
    "                               strides=[1, 2, 2, 1], \n",
    "                               padding=\"SAME\")\n",
    "    # Activation function ReLU\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Helper-function for plattening a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Helper-function for create Fully-connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input, \n",
    "                 num_input_channels, \n",
    "                 num_output, \n",
    "                 use_relu=True):\n",
    "    # Create weight and bias\n",
    "    weights = new_weight(shape=[num_input_channels, num_output])\n",
    "    biases = new_bias(num_output)\n",
    "    \n",
    "    layer = tf.linalg.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-0362a6d23ed2>:5: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, shape=[-1, img_shape[0], img_shape[1], num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "# Dropout \n",
    "tf.nn.dropout(y_true, 0.5)\n",
    "######################################################\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 2, 2, 36) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create convolution layer\n",
    "conv_layer1, weight1 = new_conv_layer(input=x_image, \n",
    "                                      num_input_channels=num_channels, \n",
    "                                      filter_size=filter1_size, \n",
    "                                      num_filters=num_filter1, \n",
    "                                      use_pooling=True)\n",
    "conv_layer2, weight2 = new_conv_layer(input=conv_layer1, \n",
    "                                      num_input_channels=num_filter1, \n",
    "                                      filter_size=filter2_size, \n",
    "                                      num_filters=num_filter2, \n",
    "                                      use_pooling=True)\n",
    "tf.nn.relu(conv_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 2, 2, 36) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 144) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten layer\n",
    "layer_flat, num_features = flatten_layer(conv_layer2)\n",
    "print(num_features)\n",
    "layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected layer\n",
    "fc_layer1 = new_fc_layer(input=layer_flat, \n",
    "                            num_input_channels=num_features, \n",
    "                            num_output=fc_size, \n",
    "                            use_relu=True)\n",
    "fc_layer2 = new_fc_layer(input=fc_layer1, \n",
    "                            num_input_channels=fc_size, \n",
    "                            num_output=num_classes, \n",
    "                            use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y_pred\n",
    "y_pred = tf.nn.softmax(fc_layer2)\n",
    "y_pred_cls= tf.math.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=fc_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.math.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size of data training.\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_test = {x: x_test,\n",
    "                  y_true: y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterator = 0 \n",
    "def optimize(iterations):\n",
    "    global num_iterator\n",
    "    for i in range(num_iterator, num_iterator + iterations):\n",
    "        x_batch, y_true_batch, _ = data.random_batch(batch_size=batch_size)\n",
    "        feed_dict_train = {x: x_batch, \n",
    "                           y_true: y_true_batch}\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        # Print training accuracy each 100 iteration.\n",
    "        # Print test accuracy each 100 iteration.\n",
    "        if (i % 100 == 0):\n",
    "            acc_train = session.run(accuracy, feed_dict_train)\n",
    "            print(\"{0}: Accuracy train: {1:<6}\".format(i, acc_train))\n",
    "\n",
    "    # Update variable count iteration training\n",
    "    num_iterator = num_iterator + iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_error(y_pred_cls, y_true_cls):\n",
    "    correct = tf.equal(y_pred_cls, y_true_cls)\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    img_incorrect = x[incorrect]\n",
    "    pred_labels = y_pred_cls[incorrect]\n",
    "    true_labels = y_true_cls[incorrect]\n",
    "    \n",
    "    plot_images[img_incorrect, true_labels, pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(pred_cls):\n",
    "    true_cls = data.y_test_cls\n",
    "    cm = confusion_matrix(pred_cls, true_cls)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_accuracy(print_confusion_matrix=False, \n",
    "                        plot_example_error=False):\n",
    "    \n",
    "    images = data.x_test\n",
    "    # Get the associated labels.\n",
    "    labels = data.y_test\n",
    "    # Create a feed-dict with these images and labels.\n",
    "    feed_dict = {x: images,\n",
    "                 y_true: labels}\n",
    "    #y_pred = session.run(y_pred_cls, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    \n",
    "    # Another way to calculate accuracy\n",
    "    #pred_label = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "    #correct = np.equal(pred_label, data.y_test_cls)\n",
    "    #print(\"Accuracy: \", float(correct.sum())/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1032\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Accuracy train: 0.125 \n"
     ]
    }
   ],
   "source": [
    "optimize(iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: Accuracy train: 0.75  \n"
     ]
    }
   ],
   "source": [
    "optimize(iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200: Accuracy train: 0.875 \n",
      "300: Accuracy train: 0.9375\n",
      "400: Accuracy train: 0.875 \n",
      "500: Accuracy train: 0.953125\n",
      "600: Accuracy train: 0.953125\n",
      "700: Accuracy train: 0.921875\n",
      "800: Accuracy train: 0.9375\n",
      "900: Accuracy train: 0.953125\n",
      "1000: Accuracy train: 0.984375\n",
      "1100: Accuracy train: 0.984375\n"
     ]
    }
   ],
   "source": [
    "optimize(iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9855\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200: Accuracy train: 0.984375\n",
      "1300: Accuracy train: 0.984375\n",
      "1400: Accuracy train: 0.96875\n",
      "1500: Accuracy train: 0.984375\n",
      "1600: Accuracy train: 1.0   \n",
      "1700: Accuracy train: 1.0   \n",
      "1800: Accuracy train: 0.96875\n",
      "1900: Accuracy train: 1.0   \n",
      "2000: Accuracy train: 0.984375\n",
      "2100: Accuracy train: 1.0   \n",
      "2200: Accuracy train: 1.0   \n",
      "2300: Accuracy train: 1.0   \n",
      "2400: Accuracy train: 1.0   \n",
      "2500: Accuracy train: 1.0   \n",
      "2600: Accuracy train: 0.984375\n",
      "2700: Accuracy train: 1.0   \n",
      "2800: Accuracy train: 1.0   \n",
      "2900: Accuracy train: 1.0   \n",
      "3000: Accuracy train: 1.0   \n",
      "3100: Accuracy train: 1.0   \n",
      "3200: Accuracy train: 1.0   \n",
      "3300: Accuracy train: 0.984375\n",
      "3400: Accuracy train: 1.0   \n",
      "3500: Accuracy train: 1.0   \n",
      "3600: Accuracy train: 0.96875\n",
      "3700: Accuracy train: 1.0   \n",
      "3800: Accuracy train: 1.0   \n",
      "3900: Accuracy train: 1.0   \n",
      "4000: Accuracy train: 1.0   \n",
      "4100: Accuracy train: 1.0   \n",
      "4200: Accuracy train: 1.0   \n",
      "4300: Accuracy train: 0.984375\n",
      "4400: Accuracy train: 0.953125\n",
      "4500: Accuracy train: 1.0   \n",
      "4600: Accuracy train: 0.984375\n",
      "4700: Accuracy train: 1.0   \n",
      "4800: Accuracy train: 0.984375\n",
      "4900: Accuracy train: 1.0   \n",
      "5000: Accuracy train: 1.0   \n",
      "5100: Accuracy train: 1.0   \n",
      "5200: Accuracy train: 1.0   \n",
      "5300: Accuracy train: 1.0   \n",
      "5400: Accuracy train: 1.0   \n",
      "5500: Accuracy train: 1.0   \n",
      "5600: Accuracy train: 1.0   \n",
      "5700: Accuracy train: 1.0   \n",
      "5800: Accuracy train: 0.984375\n",
      "5900: Accuracy train: 0.984375\n",
      "6000: Accuracy train: 1.0   \n",
      "6100: Accuracy train: 1.0   \n"
     ]
    }
   ],
   "source": [
    "optimize(iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9908\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conv_layer(layer, image):\n",
    "    # Assume layer is a TensorFlow op that outputs a 4-dim tensor\n",
    "    # which is the output of a convolutional layer,\n",
    "    # e.g. layer_conv1 or layer_conv2.\n",
    "\n",
    "    # Create a feed-dict containing just one image.\n",
    "    # Note that we don't need to feed y_true because it is\n",
    "    # not used in this calculation.\n",
    "    feed_dict = {x: [image]}\n",
    "\n",
    "    # Calculate and retrieve the output values of the layer\n",
    "    # when inputting that image.\n",
    "    values = session.run(layer, feed_dict=feed_dict)\n",
    "\n",
    "    # Number of filters used in the conv. layer.\n",
    "    num_filters = values.shape[3]\n",
    "\n",
    "    # Number of grids to plot.\n",
    "    # Rounded-up, square-root of the number of filters.\n",
    "    num_grids = math.ceil(math.sqrt(num_filters))\n",
    "    \n",
    "    # Create figure with a grid of sub-plots.\n",
    "    fig, axes = plt.subplots(num_grids, num_grids)\n",
    "\n",
    "    # Plot the output images of all the filters.\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Only plot the images for valid filters.\n",
    "        if i<num_filters:\n",
    "            # Get the output image of using the i'th filter.\n",
    "            # See new_conv_layer() for details on the format\n",
    "            # of this 4-dim tensor.\n",
    "            img = values[0, :, :, i]\n",
    "\n",
    "            # Plot image.\n",
    "            ax.imshow(img, interpolation='nearest', cmap='binary')\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = data.x_test[0]\n",
    "\n",
    "plot_conv_layer(layer=conv_layer1, image=image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.0892\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
